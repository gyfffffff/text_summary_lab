lr: 0.001
batch_size: 32
epoches: 100
patience: 50
device: cuda
optim: adam
weight_decay: 1e-4
lr_decay: 0
clip: True
max_norm: 10

model: 'lstm2lstm'
hidden_size: 128
embed_size: 128
num_layers: 2
vocab_size: 1303   # 不加1会有索引溢出

log_dir: log
res_dir: res

data_dir: data